"""
æŠ¥å‘Šç”ŸæˆæœåŠ¡
æ”¯æŒå¤šç§ LLM åç«¯ï¼šOllamaã€vLLMã€OpenAI å…¼å®¹ API
"""

import json
from typing import Dict, Any, List, Optional
from datetime import datetime
from pathlib import Path
import numpy as np

from app.core.config import settings
from app.core.logging import logger


def convert_to_json_serializable(obj: Any) -> Any:
    """
    å°†å¯¹è±¡è½¬æ¢ä¸º JSON å¯åºåˆ—åŒ–çš„æ ¼å¼
    
    å¤„ç† numpy ç±»å‹ã€Path å¯¹è±¡ç­‰
    """
    if isinstance(obj, (np.integer, np.floating)):
        return float(obj) if isinstance(obj, np.floating) else int(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (tuple, list)):
        return [convert_to_json_serializable(item) for item in obj]
    elif isinstance(obj, dict):
        return {key: convert_to_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, Path):
        return str(obj)
    elif hasattr(obj, '__dict__'):
        return convert_to_json_serializable(obj.__dict__)
    else:
        return obj


class ReportGenerator:
    """
    åŒ»å­¦å½±åƒæŠ¥å‘Šç”Ÿæˆå™¨
    
    æ”¯æŒçš„ LLM åç«¯:
    - Ollama (æœ¬åœ°éƒ¨ç½²)
    - vLLM (æœ¬åœ°éƒ¨ç½²)
    - OpenAI å…¼å®¹ API
    - ç¦»çº¿æ¨¡æ¿æ¨¡å¼ (æ— éœ€ LLM)
    """
    
    # ACR æ ‡å‡†æŠ¥å‘Šæ¨¡æ¿
    ACR_TEMPLATE = """
# {modality} å½±åƒè¯Šæ–­æŠ¥å‘Š

**æ£€æŸ¥æ—¥æœŸ**: {study_date}
**æ‚£è€… ID**: {patient_id}
**æ£€æŸ¥éƒ¨ä½**: {body_part}

---

## ä¸´åºŠä¿¡æ¯
{clinical_info}

## æŠ€æœ¯å‚æ•°
{technique}

## å½±åƒæ‰€è§
{findings}

## è¯Šæ–­å°è±¡
{impression}

## å»ºè®®
{recommendations}

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {generated_at}*
*æœ¬æŠ¥å‘Šç”± NeuroScan AI è¾…åŠ©ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œæœ€ç»ˆè¯Šæ–­è¯·ä»¥ä¸´åºŠåŒ»ç”Ÿåˆ¤æ–­ä¸ºå‡†ã€‚*
"""

    # çºµå‘å¯¹æ¯”æŠ¥å‘Šæ¨¡æ¿ï¼ˆå¢å¼ºç‰ˆï¼‰
    LONGITUDINAL_TEMPLATE = """
# {modality} çºµå‘å¯¹æ¯”åˆ†ææŠ¥å‘Š

**æ‚£è€… ID**: {patient_id}
**åŸºçº¿æ£€æŸ¥æ—¥æœŸ**: {baseline_date}
**éšè®¿æ£€æŸ¥æ—¥æœŸ**: {followup_date}
**æ£€æŸ¥é—´éš”**: {interval}

---

## æ£€æŸ¥ç›®çš„
{purpose}

## å¯¹æ¯”æ–¹æ³•
{method}

## å˜åŒ–åˆ†æ

### å®šé‡æµ‹é‡
{measurements}

### ç—…ç¶å˜åŒ–
{lesion_changes}

### RECIST 1.1 è¯„ä¼°
{recist_assessment}

## è¯Šæ–­å°è±¡
{impression}

## ä¸´åºŠå»ºè®®
{recommendations}

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {generated_at}*
*æœ¬æŠ¥å‘Šç”± NeuroScan AI è¾…åŠ©ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œæœ€ç»ˆè¯Šæ–­è¯·ä»¥ä¸´åºŠåŒ»ç”Ÿåˆ¤æ–­ä¸ºå‡†ã€‚*
*æœ¬æŠ¥å‘Šé‡‡ç”¨äººå·¥æ™ºèƒ½å›¾åƒé…å‡†å’Œå˜åŒ–æ£€æµ‹æŠ€æœ¯ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹åˆ†æç”Ÿæˆã€‚*
"""

    def __init__(self, llm_backend: str = "template"):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            llm_backend: LLM åç«¯ç±»å‹ ("ollama", "vllm", "openai", "template")
        """
        self.llm_backend = llm_backend
        self.llm_client = None
        
        if llm_backend != "template":
            self._init_llm_client()
    
    def _init_llm_client(self):
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        try:
            if self.llm_backend == "ollama":
                self._init_ollama()
            elif self.llm_backend == "vllm":
                self._init_vllm()
            elif self.llm_backend == "openai":
                self._init_openai()
            else:
                logger.warning(f"æœªçŸ¥çš„ LLM åç«¯: {self.llm_backend}, ä½¿ç”¨æ¨¡æ¿æ¨¡å¼")
                self.llm_backend = "template"
        except Exception as e:
            logger.warning(f"LLM åˆå§‹åŒ–å¤±è´¥: {e}, å›é€€åˆ°æ¨¡æ¿æ¨¡å¼")
            self.llm_backend = "template"
    
    def _safe_json_dumps(self, obj: Any) -> str:
        """å®‰å…¨åœ°å°†å¯¹è±¡è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²ï¼ˆå¤„ç† numpy ç±»å‹ï¼‰"""
        serializable_obj = convert_to_json_serializable(obj)
        return json.dumps(serializable_obj, indent=2, ensure_ascii=False)
    
    def _init_ollama(self):
        """åˆå§‹åŒ– Ollama å®¢æˆ·ç«¯"""
        try:
            import ollama
            self.llm_client = ollama
            # æµ‹è¯•è¿æ¥
            ollama.list()
            logger.info("Ollama å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            raise ImportError("è¯·å®‰è£… ollama: pip install ollama")
        except Exception as e:
            raise ConnectionError(f"æ— æ³•è¿æ¥åˆ° Ollama: {e}")
    
    def _init_vllm(self):
        """åˆå§‹åŒ– vLLM å®¢æˆ·ç«¯ (é€šè¿‡ OpenAI å…¼å®¹æ¥å£)"""
        try:
            from openai import OpenAI
            self.llm_client = OpenAI(
                base_url=settings.LLM_BASE_URL,
                api_key=settings.LLM_API_KEY
            )
            logger.info("vLLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai: pip install openai")
    
    def _init_openai(self):
        """åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI
            self.llm_client = OpenAI(
                base_url=settings.LLM_BASE_URL,
                api_key=settings.LLM_API_KEY
            )
            logger.info("OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai: pip install openai")
    
    def _clean_llm_response(self, response: str, system_prompt: str, user_prompt: str) -> str:
        """æ¸…ç† LLM è¿”å›å†…å®¹ï¼Œç§»é™¤å¯èƒ½åŒ…å«çš„ prompt æ–‡æœ¬"""
        if not response:
            return ""
        
        cleaned = response.strip()
        
        # ç§»é™¤å¸¸è§çš„ prompt æ¨¡å¼ï¼ˆå®Œæ•´åŒ¹é…ï¼‰
        prompt_patterns = [
            "ä½ æ˜¯ä¸€åä¸“æ³¨äºè‚¿ç˜¤å½±åƒçš„æ”¾å°„ç§‘åŒ»ç”Ÿã€‚è¯·æ ¹æ®çºµå‘å¯¹æ¯”æ•°æ®ç”Ÿæˆè¯¦ç»†çš„è¯Šæ–­å°è±¡ã€‚",
            "ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„è‚¿ç˜¤ç§‘åŒ»ç”Ÿã€‚è¯·æ ¹æ®å½±åƒå¯¹æ¯”ç»“æœç”Ÿæˆè¯¦ç»†çš„æ²»ç–—å»ºè®®ã€‚",
            "ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ”¾å°„ç§‘åŒ»ç”Ÿã€‚è¯·æ ¹æ®æä¾›çš„å½±åƒæ•°æ®ç”Ÿæˆä¸“ä¸šçš„è¯Šæ–­å°è±¡ã€‚",
            "ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ”¾å°„ç§‘åŒ»ç”Ÿã€‚è¯·æ ¹æ®å½±åƒå‘ç°ç”Ÿæˆåˆç†çš„ä¸´åºŠå»ºè®®ã€‚",
            "è¦æ±‚ï¼š",
            "1. ä½¿ç”¨ä¸“ä¸šçš„ä¸­æ–‡åŒ»å­¦æœ¯è¯­",
            "2. æ˜ç¡®æè¿°å˜åŒ–è¶‹åŠ¿å’Œå¹…åº¦",
            "3. å¼•ç”¨ RECIST 1.1 æ ‡å‡†è¿›è¡Œè¯„ä¼°",
            "4. ç»™å‡ºæ˜ç¡®çš„ç–—æ•ˆè¯„ä¼°",
            "5. åˆ†æé…å‡†è´¨é‡å¯¹ç»“æœçš„å½±å“",
            "6. æè¿°è¦è¯¦ç»†ã€ä¸“ä¸šã€å‡†ç¡®",
            "1. ä½¿ç”¨ä¸­æ–‡ï¼Œä¸“ä¸šæœ¯è¯­",
            "2. å»ºè®®åŸºäº RECIST è¯„ä¼°ç»“æœ",
            "3. è€ƒè™‘å¤šå­¦ç§‘åä½œ (MDT)",
            "4. ç»™å‡ºå…·ä½“çš„éšè®¿è®¡åˆ’å’Œæ—¶é—´",
            "5. è€ƒè™‘æ‚£è€…ä¸ªä½“åŒ–æ²»ç–—",
            "6. å»ºè®®è¦è¯¦ç»†ã€å¯æ“ä½œã€æœ‰é’ˆå¯¹æ€§",
            "è¯·ç”Ÿæˆè¯¦ç»†çš„çºµå‘å¯¹æ¯”è¯Šæ–­å°è±¡ï¼ˆä½¿ç”¨ä¸­æ–‡ï¼Œä¸“ä¸šæœ¯è¯­ï¼‰",
            "è¯·ç”Ÿæˆè¯¦ç»†çš„ä¸´åºŠæ²»ç–—å»ºè®®ï¼ˆä½¿ç”¨ä¸­æ–‡ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰",
            "è¯·ç”Ÿæˆè¯Šæ–­å°è±¡",
            "è¯·ç”Ÿæˆä¸´åºŠå»ºè®®",
        ]
        
        # ç§»é™¤åŒ…å« prompt çš„è¡Œ
        lines = cleaned.split('\n')
        filtered_lines = []
        
        for line in lines:
            line_stripped = line.strip()
            # è·³è¿‡ç©ºè¡Œ
            if not line_stripped:
                # ä¿ç•™ç©ºè¡Œä»¥ç»´æŒæ ¼å¼
                if filtered_lines:  # åªåœ¨å·²æœ‰å†…å®¹æ—¶ä¿ç•™ç©ºè¡Œ
                    filtered_lines.append('')
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ prompt æ¨¡å¼
            is_prompt = False
            for pattern in prompt_patterns:
                if pattern in line_stripped or line_stripped.startswith(pattern):
                    is_prompt = True
                    break
            
            # å¦‚æœä¸æ˜¯ promptï¼Œä¿ç•™è¿™ä¸€è¡Œ
            if not is_prompt:
                filtered_lines.append(line)
        
        cleaned = '\n'.join(filtered_lines).strip()
        
        # ç§»é™¤å¼€å¤´çš„"è¯Šæ–­å°è±¡"æˆ–"ä¸´åºŠå»ºè®®"æ ‡é¢˜ï¼ˆå¦‚æœåé¢è¿˜æœ‰å†…å®¹ï¼‰
        title_patterns = ["è¯Šæ–­å°è±¡", "ä¸´åºŠå»ºè®®"]
        for title in title_patterns:
            if cleaned.startswith(title):
                # æ£€æŸ¥åé¢æ˜¯å¦æœ‰å®é™…å†…å®¹
                remaining = cleaned[len(title):].strip()
                if remaining and not remaining.startswith("ä½ æ˜¯ä¸€å"):
                    cleaned = remaining
                    break
        
        # ç§»é™¤å¯èƒ½åŒ…å«çš„ JSON ä»£ç å—æ ‡è®°ï¼ˆå¦‚æœ LLM é”™è¯¯åœ°åŒ…å«äº† promptï¼‰
        if "```json" in cleaned and cleaned.count("```json") > 1:
            # æ‰¾åˆ°æœ€åä¸€ä¸ª JSON å—ä¹‹åçš„å†…å®¹
            last_json_end = cleaned.rfind("```")
            if last_json_end > 0:
                cleaned = cleaned[last_json_end + 3:].strip()
        
        return cleaned
    
    def _call_llm(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨ LLM"""
        if self.llm_backend == "template":
            return ""
        
        try:
            if self.llm_backend == "ollama":
                response = self.llm_client.chat(
                    model=settings.LLM_MODEL,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ]
                )
                # Ollama returns a ChatResponse object, not a dict
                raw_content = response.message.content
                # æ¸…ç†å“åº”å†…å®¹
                cleaned_content = self._clean_llm_response(raw_content, system_prompt, user_prompt)
                return cleaned_content
            else:
                # OpenAI å…¼å®¹æ¥å£ (vLLM, OpenAI)
                response = self.llm_client.chat.completions.create(
                    model=settings.LLM_MODEL,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=settings.LLM_TEMPERATURE,
                    max_tokens=settings.LLM_MAX_TOKENS
                )
                raw_content = response.choices[0].message.content
                # æ¸…ç†å“åº”å†…å®¹
                cleaned_content = self._clean_llm_response(raw_content, system_prompt, user_prompt)
                return cleaned_content
        except Exception as e:
            logger.error(f"LLM è°ƒç”¨å¤±è´¥: {e}")
            return ""
    
    def generate_single_report(
        self,
        patient_id: str,
        study_date: str,
        body_part: str,
        findings: List[Dict[str, Any]],
        clinical_info: str = "æœªæä¾›",
        modality: str = "CT"
    ) -> str:
        """
        ç”Ÿæˆå•æ¬¡æ‰«ææŠ¥å‘Š
        
        Args:
            patient_id: æ‚£è€… ID
            study_date: æ£€æŸ¥æ—¥æœŸ
            body_part: æ£€æŸ¥éƒ¨ä½
            findings: å‘ç°åˆ—è¡¨
            clinical_info: ä¸´åºŠä¿¡æ¯
            modality: æ£€æŸ¥æ¨¡æ€
            
        Returns:
            Markdown æ ¼å¼çš„æŠ¥å‘Š
        """
        # æ ¼å¼åŒ–å‘ç°
        findings_text = self._format_findings(findings)
        
        # ç”Ÿæˆè¯Šæ–­å°è±¡
        if self.llm_backend != "template":
            impression = self._generate_impression_with_llm(findings, body_part)
            recommendations = self._generate_recommendations_with_llm(findings, body_part)
        else:
            impression = self._generate_impression_template(findings, body_part)
            recommendations = self._generate_recommendations_template(findings)
        
        # å¡«å……æ¨¡æ¿
        report = self.ACR_TEMPLATE.format(
            modality=modality,
            study_date=study_date,
            patient_id=patient_id,
            body_part=body_part,
            clinical_info=clinical_info,
            technique=self._get_technique_text(modality),
            findings=findings_text,
            impression=impression,
            recommendations=recommendations,
            generated_at=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        )
        
        return report
    
    def generate_longitudinal_report(
        self,
        patient_id: str,
        baseline_date: str,
        followup_date: str,
        baseline_findings: List[Dict[str, Any]],
        followup_findings: List[Dict[str, Any]],
        registration_results: Dict[str, Any],
        change_results: Dict[str, Any],
        modality: str = "CT"
    ) -> str:
        """
        ç”Ÿæˆçºµå‘å¯¹æ¯”æŠ¥å‘Šï¼ˆä¸­æ–‡ï¼Œè¯¦ç»†ï¼Œä½¿ç”¨ LLM åˆ†æï¼‰
        
        Args:
            patient_id: æ‚£è€… ID
            baseline_date: åŸºçº¿æ—¥æœŸ
            followup_date: éšè®¿æ—¥æœŸ
            baseline_findings: åŸºçº¿å‘ç°
            followup_findings: éšè®¿å‘ç°
            registration_results: é…å‡†ç»“æœ
            change_results: å˜åŒ–æ£€æµ‹ç»“æœ
            modality: æ£€æŸ¥æ¨¡æ€
            
        Returns:
            Markdown æ ¼å¼çš„æŠ¥å‘Š
        """
        # è®¡ç®—é—´éš”
        interval = self._calculate_interval(baseline_date, followup_date)
        
        # æ ¼å¼åŒ–æµ‹é‡æ•°æ®ï¼ˆä¼ å…¥ change_resultsï¼‰
        measurements = self._format_measurements(baseline_findings, followup_findings, change_results)
        
        # æ ¼å¼åŒ–ç—…ç¶å˜åŒ–
        lesion_changes = self._format_lesion_changes(baseline_findings, followup_findings, change_results)
        
        # RECIST è¯„ä¼°ï¼ˆä¼ å…¥ change_resultsï¼‰
        recist_assessment = self._format_recist_assessment(baseline_findings, followup_findings, change_results)
        
        # ä½¿ç”¨ LLM åˆ†æé…å‡†ç»“æœ
        registration_analysis = ""
        if self.llm_backend != "template":
            registration_analysis = self._analyze_registration_with_llm(registration_results)
        else:
            registration_analysis = self._analyze_registration_template(registration_results)
        
        # ä½¿ç”¨ LLM åˆ†æå˜åŒ–æ£€æµ‹ç»“æœ
        change_analysis = ""
        if self.llm_backend != "template":
            change_analysis = self._analyze_changes_with_llm(change_results, baseline_findings, followup_findings)
        else:
            change_analysis = self._analyze_changes_template(change_results)
        
        # ç”Ÿæˆè¯Šæ–­å°è±¡å’Œå»ºè®®ï¼ˆä½¿ç”¨ LLMï¼‰
        if self.llm_backend != "template":
            impression = self._generate_longitudinal_impression_with_llm(
                baseline_findings, followup_findings, change_results, registration_results
            )
            recommendations = self._generate_longitudinal_recommendations_with_llm(
                baseline_findings, followup_findings, change_results, registration_results
            )
        else:
            impression = self._generate_longitudinal_impression_template(
                baseline_findings, followup_findings, change_results
            )
            recommendations = self._generate_longitudinal_recommendations_template(
                baseline_findings, followup_findings, change_results
            )
        
        # å¡«å……æ¨¡æ¿ï¼ˆå¢å¼ºç‰ˆï¼‰
        report = self.LONGITUDINAL_TEMPLATE.format(
            modality=modality,
            patient_id=patient_id,
            baseline_date=baseline_date,
            followup_date=followup_date,
            interval=interval,
            purpose="è¯„ä¼°ç—…ç¶å˜åŒ–ï¼Œåˆ¤æ–­æ²»ç–—æ•ˆæœ",
            method=f"""é‡‡ç”¨ä¸¤çº§é…å‡†ç­–ç•¥ï¼ˆåˆšæ€§é…å‡† + éåˆšæ€§é…å‡†ï¼‰è¿›è¡Œå›¾åƒå¯¹é½ï¼Œç¡®ä¿ä¸¤æ¬¡æ‰«æçš„ç²¾ç¡®å¯¹æ¯”ã€‚

**é…å‡†æ–¹æ³•**:
{registration_analysis}

**å˜åŒ–æ£€æµ‹æ–¹æ³•**:
{change_analysis}""",
            measurements=measurements,
            lesion_changes=lesion_changes,
            recist_assessment=recist_assessment,
            impression=impression,
            recommendations=recommendations,
            generated_at=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        )
        
        return report
    
    def _format_findings(self, findings: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å‘ç°åˆ—è¡¨"""
        if not findings:
            return "æœªè§æ˜æ˜¾å¼‚å¸¸ã€‚"
        
        text_parts = []
        for i, finding in enumerate(findings, 1):
            organ = finding.get("organ", "æœªçŸ¥")
            location = finding.get("location", "æœªçŸ¥")
            size = finding.get("max_diameter_mm", 0)
            volume = finding.get("volume_cc", 0)
            density = finding.get("mean_hu", 0)
            shape = finding.get("shape", "è§„åˆ™")
            density_type = finding.get("density_type", "å®æ€§")
            
            text = f"""
**ç—…ç¶ {i}**:
- ä½ç½®: {organ} {location}
- å¤§å°: æœ€å¤§ç›´å¾„çº¦ {size:.1f} mm
- ä½“ç§¯: çº¦ {volume:.2f} cc
- å¯†åº¦: å¹³å‡ CT å€¼ {density:.1f} HU ({density_type})
- å½¢æ€: {shape}
"""
            text_parts.append(text)
        
        return "\n".join(text_parts)
    
    def _format_measurements(
        self,
        baseline_findings: List[Dict[str, Any]],
        followup_findings: List[Dict[str, Any]],
        change_results: Dict[str, Any] = None
    ) -> str:
        """æ ¼å¼åŒ–æµ‹é‡æ•°æ®å¯¹æ¯”"""
        text_parts = ["| æŒ‡æ ‡ | åŸºçº¿ | éšè®¿ | å˜åŒ– |", "|------|------|------|------|"]
        
        # å¦‚æœæœ‰ change_resultsï¼Œä¼˜å…ˆä½¿ç”¨çœŸå®åˆ†ææ•°æ®
        if change_results and change_results.get("changed_voxels", 0) > 0:
            changed_voxels = change_results.get("changed_voxels", 0)
            total_voxels = change_results.get("total_voxels", 1)
            change_percent = change_results.get("change_percent", 0)
            changed_volume = change_results.get("changed_volume_cc", 0)
            max_increase = change_results.get("max_hu_increase", 0)
            max_decrease = change_results.get("max_hu_decrease", 0)
            mean_change = change_results.get("mean_hu_change", 0)
            
            text_parts.append(f"| å˜åŒ–ä½“ç´ æ•° | - | - | {changed_voxels:,} |")
            text_parts.append(f"| å˜åŒ–æ¯”ä¾‹ | - | - | {change_percent:.2f}% |")
            text_parts.append(f"| å˜åŒ–ä½“ç§¯ (cc) | - | - | {changed_volume:.2f} |")
            text_parts.append(f"| æœ€å¤§å¯†åº¦å¢åŠ  (HU) | - | - | +{max_increase:.1f} |")
            text_parts.append(f"| æœ€å¤§å¯†åº¦å‡å°‘ (HU) | - | - | {max_decrease:.1f} |")
            text_parts.append(f"| å¹³å‡å¯†åº¦å˜åŒ– (HU) | - | - | {mean_change:+.1f} |")
            
            return "\n".join(text_parts)
        
        # å¦‚æœæ²¡æœ‰ change_resultsï¼Œä½¿ç”¨ç—…ç¶æ•°æ®
        if not baseline_findings and not followup_findings:
            return "æ— å¯æµ‹é‡ç—…ç¶æ•°æ®ï¼Œè¯·æŸ¥çœ‹å˜åŒ–æ£€æµ‹ç»Ÿè®¡ã€‚"
        
        # å‡è®¾ç¬¬ä¸€ä¸ªç—…ç¶æ˜¯ç›®æ ‡ç—…ç¶
        baseline = baseline_findings[0] if baseline_findings else {}
        followup = followup_findings[0] if followup_findings else {}
        
        # ç›´å¾„
        b_diameter = baseline.get("max_diameter_mm", 0)
        f_diameter = followup.get("max_diameter_mm", 0)
        d_change = ((f_diameter - b_diameter) / b_diameter * 100) if b_diameter > 0 else 0
        text_parts.append(f"| æœ€å¤§ç›´å¾„ (mm) | {b_diameter:.1f} | {f_diameter:.1f} | {d_change:+.1f}% |")
        
        # ä½“ç§¯
        b_volume = baseline.get("volume_cc", 0)
        f_volume = followup.get("volume_cc", 0)
        v_change = ((f_volume - b_volume) / b_volume * 100) if b_volume > 0 else 0
        text_parts.append(f"| ä½“ç§¯ (cc) | {b_volume:.2f} | {f_volume:.2f} | {v_change:+.1f}% |")
        
        # å¯†åº¦
        b_hu = baseline.get("mean_hu", 0)
        f_hu = followup.get("mean_hu", 0)
        hu_change = f_hu - b_hu
        text_parts.append(f"| å¹³å‡å¯†åº¦ (HU) | {b_hu:.1f} | {f_hu:.1f} | {hu_change:+.1f} |")
        
        return "\n".join(text_parts)
    
    def _format_lesion_changes(
        self,
        baseline_findings: List[Dict[str, Any]],
        followup_findings: List[Dict[str, Any]],
        change_results: Dict[str, Any]
    ) -> str:
        """æ ¼å¼åŒ–ç—…ç¶å˜åŒ–æè¿°"""
        # ä¼˜å…ˆä½¿ç”¨ change_results ä¸­çš„çœŸå®æ•°æ®
        if change_results and change_results.get("changed_voxels", 0) > 0:
            changed_voxels = change_results.get("changed_voxels", 0)
            total_voxels = change_results.get("total_voxels", 1)
            change_percent = change_results.get("change_percent", 0)
            changed_volume = change_results.get("changed_volume_cc", 0)
            max_increase = change_results.get("max_hu_increase", 0)
            max_decrease = abs(change_results.get("max_hu_decrease", 0))
            increase_percent = change_results.get("increase_percent", 0)
            decrease_percent = change_results.get("decrease_percent", 0)
            
            # æ ¹æ®å˜åŒ–æƒ…å†µåˆ¤æ–­è¶‹åŠ¿
            if increase_percent > decrease_percent * 1.5:
                trend = "å¯†åº¦å¢åŠ ä¸ºä¸»"
                trend_desc = "å¯èƒ½æç¤ºç»„ç»‡è‡´å¯†åŒ–æˆ–æ–°å‘ç—…å˜"
            elif decrease_percent > increase_percent * 1.5:
                trend = "å¯†åº¦å‡å°‘ä¸ºä¸»"
                trend_desc = "å¯èƒ½æç¤ºç»„ç»‡ç–æ¾åŒ–æˆ–ç—…ç¶æ¶ˆé€€"
            else:
                trend = "åŒå‘å˜åŒ–"
                trend_desc = "åŒæ—¶å­˜åœ¨å¯†åº¦å¢åŠ å’Œå‡å°‘åŒºåŸŸ"
            
            text = f"""
**å…¨å±€å˜åŒ–åˆ†æ**:
- å˜åŒ–ä½“ç´ æ•°: {changed_voxels:,} / {total_voxels:,} ({change_percent:.2f}%)
- å˜åŒ–ä½“ç§¯: {changed_volume:.2f} cc
- å¯†åº¦å¢åŠ åŒºåŸŸ: {increase_percent:.2f}% (æœ€å¤§ +{max_increase:.1f} HU)
- å¯†åº¦å‡å°‘åŒºåŸŸ: {decrease_percent:.2f}% (æœ€å¤§ -{max_decrease:.1f} HU)
- å˜åŒ–è¶‹åŠ¿: **{trend}**
- ä¸´åºŠæ„ä¹‰: {trend_desc}
"""
            return text
        
        # å¦‚æœæ²¡æœ‰ change_resultsï¼Œä½¿ç”¨ç—…ç¶æ•°æ®
        if not baseline_findings and not followup_findings:
            return "æ— ç—…ç¶å˜åŒ–è®°å½•ï¼Œè¯·å‚è€ƒå˜åŒ–æ£€æµ‹ç»Ÿè®¡æ•°æ®ã€‚"
        
        baseline = baseline_findings[0] if baseline_findings else {}
        followup = followup_findings[0] if followup_findings else {}
        
        b_diameter = baseline.get("max_diameter_mm", 0)
        f_diameter = followup.get("max_diameter_mm", 0)
        d_change = ((f_diameter - b_diameter) / b_diameter * 100) if b_diameter > 0 else 0
        
        # æè¿°å˜åŒ–
        if d_change > 20:
            change_desc = "æ˜æ˜¾å¢å¤§"
            trend = "è¿›å±•"
        elif d_change < -30:
            change_desc = "æ˜æ˜¾ç¼©å°"
            trend = "ç¼“è§£"
        elif d_change < -10:
            change_desc = "ç•¥æœ‰ç¼©å°"
            trend = "å¯èƒ½ç¼“è§£"
        elif d_change > 10:
            change_desc = "ç•¥æœ‰å¢å¤§"
            trend = "å¯èƒ½è¿›å±•"
        else:
            change_desc = "å¤§å°ç¨³å®š"
            trend = "ç¨³å®š"
        
        organ = followup.get("organ", baseline.get("organ", "æœªçŸ¥"))
        location = followup.get("location", baseline.get("location", "æœªçŸ¥"))
        
        text = f"""
**ç›®æ ‡ç—…ç¶** ({organ} {location}):
- åŸºçº¿ç›´å¾„: {b_diameter:.1f} mm
- éšè®¿ç›´å¾„: {f_diameter:.1f} mm
- å˜åŒ–å¹…åº¦: {d_change:+.1f}%
- å˜åŒ–è¶‹åŠ¿: **{change_desc}** ({trend})
"""
        return text
    
    def _format_recist_assessment(
        self,
        baseline_findings: List[Dict[str, Any]],
        followup_findings: List[Dict[str, Any]],
        change_results: Dict[str, Any] = None
    ) -> str:
        """æ ¼å¼åŒ– RECIST 1.1 è¯„ä¼°"""
        # å¦‚æœæœ‰ change_resultsï¼ŒåŸºäºå˜åŒ–æ£€æµ‹ç»“æœè¿›è¡Œè¯„ä¼°
        if change_results and change_results.get("changed_voxels", 0) > 0:
            change_percent = change_results.get("change_percent", 0)
            increase_percent = change_results.get("increase_percent", 0)
            decrease_percent = change_results.get("decrease_percent", 0)
            
            # åŸºäºä½“ç§¯/å¯†åº¦å˜åŒ–è¿›è¡Œ RECIST ç±»ä¼¼è¯„ä¼°
            net_change = increase_percent - decrease_percent
            
            if change_percent < 1.0:
                response = "SD (ç–¾ç—…ç¨³å®š)"
                description = "æ€»ä½“å˜åŒ–æå° (<1%)"
                color = "ğŸŸ¢"
            elif net_change > 10:
                response = "PD (ç–¾ç—…è¿›å±•)"
                description = f"å¯†åº¦å¢åŠ åŒºåŸŸæ˜¾è‘—å¤šäºå‡å°‘åŒºåŸŸ (å‡€å˜åŒ– +{net_change:.1f}%)"
                color = "ğŸ”´"
            elif net_change < -10:
                response = "PR (éƒ¨åˆ†ç¼“è§£)"
                description = f"å¯†åº¦å‡å°‘åŒºåŸŸæ˜¾è‘—å¤šäºå¢åŠ åŒºåŸŸ (å‡€å˜åŒ– {net_change:.1f}%)"
                color = "ğŸŸ¡"
            else:
                response = "SD (ç–¾ç—…ç¨³å®š)"
                description = f"å˜åŒ–åŒºåŸŸç›¸å¯¹å¹³è¡¡ (å‡€å˜åŒ– {net_change:+.1f}%)"
                color = "ğŸŸ "
            
            text = f"""
**RECIST 1.1 ç±»ä¼¼è¯„ä¼°**: {color} **{response}**

- è¯„ä¼°ä¾æ®: {description}
- æ€»å˜åŒ–æ¯”ä¾‹: {change_percent:.2f}%
- å¯†åº¦å¢åŠ åŒºåŸŸ: {increase_percent:.2f}%
- å¯†åº¦å‡å°‘åŒºåŸŸ: {decrease_percent:.2f}%

**æ³¨æ„**: æ­¤è¯„ä¼°åŸºäºä½“ç´ çº§å˜åŒ–æ£€æµ‹ï¼Œéæ ‡å‡†RECISTæµ‹é‡ã€‚æ ‡å‡†RECISTéœ€è¦æµ‹é‡é¶ç—…ç¶æœ€å¤§ç›´å¾„ã€‚

**RECIST 1.1 æ ‡å‡†å‚è€ƒ**:
- CR (å®Œå…¨ç¼“è§£): æ‰€æœ‰é¶ç—…ç¶æ¶ˆå¤±
- PR (éƒ¨åˆ†ç¼“è§£): é¶ç—…ç¶å¾„çº¿å’Œå‡å°‘ â‰¥30%
- SD (ç–¾ç—…ç¨³å®š): ä»‹äº PR å’Œ PD ä¹‹é—´
- PD (ç–¾ç—…è¿›å±•): é¶ç—…ç¶å¾„çº¿å’Œå¢åŠ  â‰¥20% æˆ–å‡ºç°æ–°ç—…ç¶
"""
            return text
        
        # ä½¿ç”¨ç—…ç¶æ•°æ®è¿›è¡Œæ ‡å‡†è¯„ä¼°
        if not baseline_findings or not followup_findings:
            return "æ— æ³•è¿›è¡Œæ ‡å‡† RECIST è¯„ä¼° (ç¼ºå°‘é¶ç—…ç¶æµ‹é‡æ•°æ®)ã€‚å¦‚æœ‰å˜åŒ–æ£€æµ‹ç»“æœï¼Œè¯·å‚è€ƒä¸Šæ–¹åˆ†æã€‚"
        
        baseline = baseline_findings[0]
        followup = followup_findings[0]
        
        b_diameter = baseline.get("max_diameter_mm", 0)
        f_diameter = followup.get("max_diameter_mm", 0)
        
        if b_diameter == 0:
            return "æ— æ³•è¿›è¡Œ RECIST è¯„ä¼° (åŸºçº¿æ•°æ®æ— æ•ˆ)ã€‚"
        
        change_pct = (f_diameter - b_diameter) / b_diameter * 100
        
        # RECIST 1.1 è¯„ä¼°æ ‡å‡†
        if f_diameter == 0:
            response = "CR (å®Œå…¨ç¼“è§£)"
            description = "æ‰€æœ‰é¶ç—…ç¶æ¶ˆå¤±"
            color = "ğŸŸ¢"
        elif change_pct <= -30:
            response = "PR (éƒ¨åˆ†ç¼“è§£)"
            description = "é¶ç—…ç¶å¾„çº¿å’Œå‡å°‘ â‰¥30%"
            color = "ğŸŸ¡"
        elif change_pct >= 20:
            response = "PD (ç–¾ç—…è¿›å±•)"
            description = "é¶ç—…ç¶å¾„çº¿å’Œå¢åŠ  â‰¥20%"
            color = "ğŸ”´"
        else:
            response = "SD (ç–¾ç—…ç¨³å®š)"
            description = "ä»‹äº PR å’Œ PD ä¹‹é—´"
            color = "ğŸŸ "
        
        text = f"""
**RECIST 1.1 è¯„ä¼°ç»“æœ**: {color} **{response}**

- è¯„ä¼°ä¾æ®: {description}
- å®é™…å˜åŒ–: {change_pct:+.1f}%
- åŸºçº¿å¾„çº¿å’Œ: {b_diameter:.1f} mm
- éšè®¿å¾„çº¿å’Œ: {f_diameter:.1f} mm

**è¯„ä¼°æ ‡å‡†å‚è€ƒ**:
- CR (å®Œå…¨ç¼“è§£): æ‰€æœ‰é¶ç—…ç¶æ¶ˆå¤±
- PR (éƒ¨åˆ†ç¼“è§£): é¶ç—…ç¶å¾„çº¿å’Œå‡å°‘ â‰¥30%
- SD (ç–¾ç—…ç¨³å®š): ä»‹äº PR å’Œ PD ä¹‹é—´
- PD (ç–¾ç—…è¿›å±•): é¶ç—…ç¶å¾„çº¿å’Œå¢åŠ  â‰¥20% æˆ–å‡ºç°æ–°ç—…ç¶
"""
        return text
    
    def _generate_impression_template(
        self,
        findings: List[Dict[str, Any]],
        body_part: str
    ) -> str:
        """ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆè¯Šæ–­å°è±¡"""
        if not findings:
            return f"{body_part}æ‰«ææœªè§æ˜æ˜¾å¼‚å¸¸ã€‚"
        
        impressions = []
        for i, finding in enumerate(findings, 1):
            organ = finding.get("organ", "æœªçŸ¥éƒ¨ä½")
            size = finding.get("max_diameter_mm", 0)
            density_type = finding.get("density_type", "å®æ€§")
            shape = finding.get("shape", "è§„åˆ™")
            
            if size < 6:
                nature = "å¾®å°ç»“èŠ‚ï¼Œæ€§è´¨å¾…å®š"
            elif size < 10:
                nature = "å°ç»“èŠ‚ï¼Œå»ºè®®éšè®¿"
            elif size < 30:
                nature = "ç»“èŠ‚ï¼Œå»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥"
            else:
                nature = "è‚¿å—ï¼Œé«˜åº¦å»ºè®®æ´»æ£€"
            
            impressions.append(f"{i}. {organ}å¯è§{density_type}{shape}ç»“èŠ‚ï¼Œå¤§å°çº¦ {size:.1f}mmï¼Œ{nature}ã€‚")
        
        return "\n".join(impressions)
    
    def _generate_recommendations_template(self, findings: List[Dict[str, Any]]) -> str:
        """ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆå»ºè®®"""
        if not findings:
            return "1. å®šæœŸä½“æ£€\n2. å¦‚æœ‰ä¸é€‚ï¼ŒåŠæ—¶å°±è¯Š"
        
        max_size = max(f.get("max_diameter_mm", 0) for f in findings)
        
        if max_size < 6:
            return """1. å»ºè®® 12 ä¸ªæœˆåå¤æŸ¥ CT
2. å¦‚æœ‰å’³å—½ã€èƒ¸ç—›ç­‰ç—‡çŠ¶ï¼ŒåŠæ—¶å°±è¯Š"""
        elif max_size < 10:
            return """1. å»ºè®® 6 ä¸ªæœˆåå¤æŸ¥ CT
2. å¿…è¦æ—¶è¡Œ PET-CT æ£€æŸ¥
3. å¯†åˆ‡å…³æ³¨ç—‡çŠ¶å˜åŒ–"""
        elif max_size < 30:
            return """1. å»ºè®® 3 ä¸ªæœˆåå¤æŸ¥ CT
2. å»ºè®®è¡Œ PET-CT æ£€æŸ¥
3. å¿…è¦æ—¶è¡Œç©¿åˆºæ´»æ£€
4. å»ºè®®å¤šå­¦ç§‘ä¼šè¯Š (MDT)"""
        else:
            return """1. å»ºè®®å°½å¿«è¡Œç©¿åˆºæ´»æ£€æ˜ç¡®æ€§è´¨
2. å»ºè®®è¡Œ PET-CT å…¨èº«æ£€æŸ¥
3. å»ºè®®å¤šå­¦ç§‘ä¼šè¯Š (MDT)
4. å¦‚ç¡®è¯Šæ¶æ€§ï¼Œå°½æ—©åˆ¶å®šæ²»ç–—æ–¹æ¡ˆ"""
    
    def _generate_longitudinal_impression_template(
        self,
        baseline_findings: List[Dict[str, Any]],
        followup_findings: List[Dict[str, Any]],
        change_results: Dict[str, Any]
    ) -> str:
        """ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆçºµå‘å¯¹æ¯”è¯Šæ–­å°è±¡"""
        # ä¼˜å…ˆä½¿ç”¨ change_results æ•°æ®
        if change_results and change_results.get("changed_voxels", 0) > 0:
            change_percent = change_results.get("change_percent", 0)
            changed_volume = change_results.get("changed_volume_cc", 0)
            increase_percent = change_results.get("increase_percent", 0)
            decrease_percent = change_results.get("decrease_percent", 0)
            max_increase = change_results.get("max_hu_increase", 0)
            max_decrease = abs(change_results.get("max_hu_decrease", 0))
            
            net_change = increase_percent - decrease_percent
            
            if change_percent < 1.0:
                status = "åŸºæœ¬ç¨³å®š"
                assessment = "SD (ç–¾ç—…ç¨³å®š)"
                recommendation = "ç»§ç»­å½“å‰æ–¹æ¡ˆæˆ–è§‚å¯Ÿ"
            elif net_change > 10:
                status = "å¯†åº¦å¢åŠ ä¸ºä¸»çš„å˜åŒ–"
                assessment = "å¯èƒ½æç¤ºç—…æƒ…è¿›å±•"
                recommendation = "å»ºè®®è¿›ä¸€æ­¥è¯„ä¼°ï¼Œå¿…è¦æ—¶è°ƒæ•´æ–¹æ¡ˆ"
            elif net_change < -10:
                status = "å¯†åº¦å‡å°‘ä¸ºä¸»çš„å˜åŒ–"
                assessment = "å¯èƒ½æç¤ºç—…æƒ…æ”¹å–„"
                recommendation = "ç»§ç»­å½“å‰æ²»ç–—æ–¹æ¡ˆ"
            else:
                status = "å­˜åœ¨åŒå‘å˜åŒ–"
                assessment = "éœ€ç»“åˆä¸´åºŠç»¼åˆåˆ¤æ–­"
                recommendation = "å»ºè®®çŸ­æœŸå†…å¤æŸ¥"
            
            return f"""**çºµå‘å¯¹æ¯”åˆ†æç»“è®º**:

ä¸å‰ç‰‡å¯¹æ¯”ï¼Œæ‰«æåŒºåŸŸå‘ˆç°{status}ã€‚

**å®šé‡åˆ†æ**:
- æ€»å˜åŒ–æ¯”ä¾‹: {change_percent:.2f}%
- å˜åŒ–ä½“ç§¯: {changed_volume:.2f} cc
- å¯†åº¦å¢åŠ åŒºåŸŸå æ¯”: {increase_percent:.2f}% (æœ€å¤§å¢åŠ  +{max_increase:.1f} HU)
- å¯†åº¦å‡å°‘åŒºåŸŸå æ¯”: {decrease_percent:.2f}% (æœ€å¤§å‡å°‘ -{max_decrease:.1f} HU)

**è¯„ä¼°**: {assessment}
**å»ºè®®**: {recommendation}"""
        
        # ä½¿ç”¨ç—…ç¶æ•°æ®
        if not baseline_findings or not followup_findings:
            return "å¯¹æ¯”æ•°æ®ä¸å®Œæ•´ï¼Œè¯·ç¡®ä¿å®Œæˆé…å‡†å’Œå˜åŒ–æ£€æµ‹åˆ†æã€‚"
        
        baseline = baseline_findings[0]
        followup = followup_findings[0]
        
        b_diameter = baseline.get("max_diameter_mm", 0)
        f_diameter = followup.get("max_diameter_mm", 0)
        change_pct = ((f_diameter - b_diameter) / b_diameter * 100) if b_diameter > 0 else 0
        
        organ = followup.get("organ", baseline.get("organ", ""))
        
        if change_pct > 20:
            return f"""ä¸å‰ç‰‡å¯¹æ¯”ï¼Œ{organ}ç—…ç¶æ˜æ˜¾å¢å¤§ï¼Œç›´å¾„å¢åŠ  {change_pct:.1f}%ï¼Œç¬¦åˆ RECIST 1.1 ç–¾ç—…è¿›å±• (PD) æ ‡å‡†ã€‚
æç¤ºç—…æƒ…è¿›å±•ï¼Œå»ºè®®è°ƒæ•´æ²»ç–—æ–¹æ¡ˆã€‚"""
        elif change_pct < -30:
            return f"""ä¸å‰ç‰‡å¯¹æ¯”ï¼Œ{organ}ç—…ç¶æ˜æ˜¾ç¼©å°ï¼Œç›´å¾„å‡å°‘ {abs(change_pct):.1f}%ï¼Œç¬¦åˆ RECIST 1.1 éƒ¨åˆ†ç¼“è§£ (PR) æ ‡å‡†ã€‚
æç¤ºæ²»ç–—æœ‰æ•ˆï¼Œå»ºè®®ç»§ç»­å½“å‰æ²»ç–—æ–¹æ¡ˆã€‚"""
        else:
            return f"""ä¸å‰ç‰‡å¯¹æ¯”ï¼Œ{organ}ç—…ç¶å¤§å°åŸºæœ¬ç¨³å®šï¼Œç›´å¾„å˜åŒ– {change_pct:+.1f}%ï¼Œç¬¦åˆ RECIST 1.1 ç–¾ç—…ç¨³å®š (SD) æ ‡å‡†ã€‚
å»ºè®®ç»§ç»­éšè®¿è§‚å¯Ÿã€‚"""
    
    def _generate_longitudinal_recommendations_template(
        self,
        baseline_findings: List[Dict[str, Any]],
        followup_findings: List[Dict[str, Any]],
        change_results: Dict[str, Any]
    ) -> str:
        """ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆçºµå‘å¯¹æ¯”å»ºè®®"""
        # ä¼˜å…ˆä½¿ç”¨ change_results æ•°æ®
        if change_results and change_results.get("changed_voxels", 0) > 0:
            change_percent = change_results.get("change_percent", 0)
            increase_percent = change_results.get("increase_percent", 0)
            decrease_percent = change_results.get("decrease_percent", 0)
            net_change = increase_percent - decrease_percent
            
            if change_percent < 1.0:
                return """**ä¸´åºŠå»ºè®®**:

1. ç—…æƒ…ç¨³å®šï¼Œå¯ç»§ç»­å½“å‰æ²»ç–—æ–¹æ¡ˆæˆ–è§‚å¯Ÿ
2. å»ºè®® 3 ä¸ªæœˆåå¤æŸ¥ CT è¯„ä¼°
3. å®šæœŸç›‘æµ‹è‚¿ç˜¤æ ‡å¿—ç‰©
4. å¦‚å‡ºç°æ–°ç—‡çŠ¶è¯·åŠæ—¶å°±è¯Š
5. ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼"""
            elif net_change > 10:
                return """**ä¸´åºŠå»ºè®®**:

1. âš ï¸ å»ºè®®å¤šå­¦ç§‘ä¼šè¯Š (MDT) è®¨è®º
2. è¯„ä¼°å½“å‰æ²»ç–—æ–¹æ¡ˆæœ‰æ•ˆæ€§
3. è€ƒè™‘è°ƒæ•´æ²»ç–—ç­–ç•¥æˆ–åŠ å¼ºæ²»ç–—
4. å»ºè®® 4-6 å‘¨åçŸ­æœŸå¤æŸ¥
5. å¿…è¦æ—¶è¡Œ PET-CT æˆ–å¢å¼ºæ‰«æ
6. å¦‚æœ‰é¶å‘æ²»ç–—æŒ‡å¾ï¼Œå»ºè®®åŸºå› æ£€æµ‹"""
            elif net_change < -10:
                return """**ä¸´åºŠå»ºè®®**:

1. âœ… æ²»ç–—æ•ˆæœè‰¯å¥½ï¼Œç»§ç»­å½“å‰æ–¹æ¡ˆ
2. å»ºè®® 2-3 ä¸ªæœˆåå¤æŸ¥è¯„ä¼°
3. å…³æ³¨æ²»ç–—ç›¸å…³å‰¯ä½œç”¨
4. å®šæœŸç›‘æµ‹è‚¿ç˜¤æ ‡å¿—ç‰©
5. ç»´æŒè‰¯å¥½çš„è¥å…»çŠ¶æ€å’Œç”Ÿæ´»è´¨é‡"""
            else:
                return """**ä¸´åºŠå»ºè®®**:

1. å˜åŒ–è¶‹åŠ¿ä¸æ˜ç¡®ï¼Œå»ºè®®å¯†åˆ‡éšè®¿
2. å»ºè®® 6-8 å‘¨åçŸ­æœŸå¤æŸ¥
3. ç»“åˆä¸´åºŠç—‡çŠ¶ç»¼åˆåˆ¤æ–­
4. å¿…è¦æ—¶è¡Œå¢å¼º CT æˆ– PET-CT
5. å®šæœŸç›‘æµ‹è‚¿ç˜¤æ ‡å¿—ç‰©
6. å¦‚ç—‡çŠ¶åŠ é‡è¯·åŠæ—¶å°±è¯Š"""
        
        # ä½¿ç”¨ç—…ç¶æ•°æ®
        if not baseline_findings or not followup_findings:
            return """**ä¸´åºŠå»ºè®®**:

1. å®Œå–„æ£€æŸ¥æ•°æ®ï¼Œè¿›è¡Œå®Œæ•´å¯¹æ¯”åˆ†æ
2. å¦‚æœ‰ç–‘é—®ï¼Œå»ºè®®ä¸´åºŠåŒ»ç”Ÿç»¼åˆåˆ¤æ–­
3. å®šæœŸå¤æŸ¥éšè®¿"""
        
        baseline = baseline_findings[0]
        followup = followup_findings[0]
        
        b_diameter = baseline.get("max_diameter_mm", 0)
        f_diameter = followup.get("max_diameter_mm", 0)
        change_pct = ((f_diameter - b_diameter) / b_diameter * 100) if b_diameter > 0 else 0
        
        if change_pct > 20:
            return """1. å»ºè®®å¤šå­¦ç§‘ä¼šè¯Š (MDT) è®¨è®ºæ²»ç–—æ–¹æ¡ˆè°ƒæ•´
2. è€ƒè™‘æ›´æ¢æ²»ç–—æ–¹æ¡ˆæˆ–åŠ å¼ºæ²»ç–—
3. å»ºè®® 4-6 å‘¨åå¤æŸ¥è¯„ä¼°
4. å¿…è¦æ—¶è¡ŒåŸºå› æ£€æµ‹æŒ‡å¯¼é¶å‘æ²»ç–—"""
        elif change_pct < -30:
            return """1. ç»§ç»­å½“å‰æ²»ç–—æ–¹æ¡ˆ
2. å»ºè®® 2-3 ä¸ªæœˆåå¤æŸ¥è¯„ä¼°
3. å…³æ³¨æ²»ç–—ç›¸å…³å‰¯ä½œç”¨
4. å®šæœŸç›‘æµ‹è‚¿ç˜¤æ ‡å¿—ç‰©"""
        else:
            return """1. ç»§ç»­å½“å‰æ²»ç–—æ–¹æ¡ˆæˆ–è§‚å¯Ÿ
2. å»ºè®® 2-3 ä¸ªæœˆåå¤æŸ¥
3. å¦‚å‡ºç°ç—‡çŠ¶å˜åŒ–åŠæ—¶å°±è¯Š
4. å®šæœŸç›‘æµ‹è‚¿ç˜¤æ ‡å¿—ç‰©"""
    
    def _generate_impression_with_llm(
        self,
        findings: List[Dict[str, Any]],
        body_part: str
    ) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆè¯Šæ–­å°è±¡"""
        system_prompt = """ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ”¾å°„ç§‘åŒ»ç”Ÿã€‚è¯·æ ¹æ®æä¾›çš„å½±åƒæ•°æ®ç”Ÿæˆä¸“ä¸šçš„è¯Šæ–­å°è±¡ã€‚
è¦æ±‚ï¼š
1. ä½¿ç”¨ä¸“ä¸šçš„åŒ»å­¦æœ¯è¯­
2. æè¿°å‡†ç¡®ã€ç®€æ´
3. æŒ‰é‡è¦æ€§æ’åº
4. ä¸è¦è‡†é€ æ•°æ®"""
        
        user_prompt = f"""æ£€æŸ¥éƒ¨ä½: {body_part}
å‘ç°æ•°æ®:
```json
{self._safe_json_dumps(findings)}
```

è¯·ç”Ÿæˆè¯Šæ–­å°è±¡:"""
        
        result = self._call_llm(system_prompt, user_prompt)
        return result if result else self._generate_impression_template(findings, body_part)
    
    def _generate_recommendations_with_llm(
        self,
        findings: List[Dict[str, Any]],
        body_part: str
    ) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆå»ºè®®"""
        system_prompt = """ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ”¾å°„ç§‘åŒ»ç”Ÿã€‚è¯·æ ¹æ®å½±åƒå‘ç°ç”Ÿæˆåˆç†çš„ä¸´åºŠå»ºè®®ã€‚
è¦æ±‚ï¼š
1. å»ºè®®å…·ä½“å¯è¡Œ
2. æŒ‰ä¼˜å…ˆçº§æ’åº
3. è€ƒè™‘æ‚£è€…å®‰å…¨"""
        
        user_prompt = f"""æ£€æŸ¥éƒ¨ä½: {body_part}
å‘ç°æ•°æ®:
```json
{self._safe_json_dumps(findings)}
```

è¯·ç”Ÿæˆä¸´åºŠå»ºè®®:"""
        
        result = self._call_llm(system_prompt, user_prompt)
        return result if result else self._generate_recommendations_template(findings)
    
    def _analyze_registration_with_llm(self, registration_results: Dict[str, Any]) -> str:
        """ä½¿ç”¨ LLM åˆ†æé…å‡†ç»“æœ"""
        system_prompt = """ä½ æ˜¯ä¸€ååŒ»å­¦å½±åƒæŠ€æœ¯ä¸“å®¶ã€‚è¯·åˆ†æå›¾åƒé…å‡†çš„è´¨é‡å’Œå¯é æ€§ã€‚
è¦æ±‚ï¼š
1. è¯„ä¼°é…å‡†ç²¾åº¦
2. è¯´æ˜é…å‡†æ–¹æ³•çš„ä¼˜åŠ¿
3. æŒ‡å‡ºå¯èƒ½çš„å±€é™æ€§"""
        
        user_prompt = f"""é…å‡†ç»“æœ:
```json
{self._safe_json_dumps(registration_results)}
```

è¯·åˆ†æé…å‡†è´¨é‡:"""
        
        result = self._call_llm(system_prompt, user_prompt)
        return result if result else self._analyze_registration_template(registration_results)
    
    def _analyze_registration_template(self, registration_results: Dict[str, Any]) -> str:
        """ä½¿ç”¨æ¨¡æ¿åˆ†æé…å‡†ç»“æœ"""
        return """- **åˆšæ€§é…å‡†**: ä¿®æ­£ä½“ä½å·®å¼‚ï¼Œå¯¹é½è§£å‰–ç»“æ„
- **éåˆšæ€§é…å‡†**: ä¿®æ­£å‘¼å¸ç­‰è½¯ç»„ç»‡å½¢å˜
- **é…å‡†ç²¾åº¦**: äºšæ¯«ç±³çº§ç²¾åº¦ï¼Œç¡®ä¿ç²¾ç¡®å¯¹æ¯”"""
    
    def _analyze_changes_with_llm(
        self,
        change_results: Dict[str, Any],
        baseline_findings: List[Dict[str, Any]],
        followup_findings: List[Dict[str, Any]]
    ) -> str:
        """ä½¿ç”¨ LLM åˆ†æå˜åŒ–æ£€æµ‹ç»“æœ"""
        system_prompt = """ä½ æ˜¯ä¸€ååŒ»å­¦å½±åƒåˆ†æä¸“å®¶ã€‚è¯·åˆ†æä¸¤æ¬¡æ‰«æä¹‹é—´çš„å˜åŒ–ã€‚
è¦æ±‚ï¼š
1. æè¿°å˜åŒ–çš„ç©ºé—´åˆ†å¸ƒ
2. é‡åŒ–å˜åŒ–å¹…åº¦
3. è¯„ä¼°å˜åŒ–çš„ä¸´åºŠæ„ä¹‰"""
        
        user_prompt = f"""å˜åŒ–æ£€æµ‹ç»“æœ:
```json
{self._safe_json_dumps(change_results)}
```

åŸºçº¿å‘ç°:
```json
{self._safe_json_dumps(baseline_findings)}
```

éšè®¿å‘ç°:
```json
{self._safe_json_dumps(followup_findings)}
```

è¯·åˆ†æå˜åŒ–ç‰¹å¾:"""
        
        result = self._call_llm(system_prompt, user_prompt)
        return result if result else self._analyze_changes_template(change_results)
    
    def _analyze_changes_template(self, change_results: Dict[str, Any]) -> str:
        """ä½¿ç”¨æ¨¡æ¿åˆ†æå˜åŒ–æ£€æµ‹ç»“æœ"""
        changed_voxels = change_results.get("changed_voxels", 0)
        change_percent = change_results.get("change_percent", 0)
        max_increase = change_results.get("max_hu_increase", 0)
        max_decrease = change_results.get("max_hu_decrease", 0)
        
        return f"""- **å˜åŒ–ä½“ç´ æ•°**: {changed_voxels:,} ä¸ªä½“ç´ 
- **å˜åŒ–æ¯”ä¾‹**: {change_percent:.2f}%
- **æœ€å¤§å¯†åº¦å¢åŠ **: {max_increase:.1f} HU
- **æœ€å¤§å¯†åº¦å‡å°‘**: {max_decrease:.1f} HU
- **åˆ†ææ–¹æ³•**: ä½“ç´ çº§å·®å¼‚è®¡ç®—ï¼Œé˜ˆå€¼è¿‡æ»¤"""
    
    def _generate_longitudinal_impression_with_llm(
        self,
        baseline_findings: List[Dict[str, Any]],
        followup_findings: List[Dict[str, Any]],
        change_results: Dict[str, Any],
        registration_results: Dict[str, Any] = None
    ) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆçºµå‘å¯¹æ¯”è¯Šæ–­å°è±¡ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        system_prompt = """ä½ æ˜¯ä¸€åä¸“æ³¨äºè‚¿ç˜¤å½±åƒçš„æ”¾å°„ç§‘åŒ»ç”Ÿã€‚è¯·æ ¹æ®çºµå‘å¯¹æ¯”æ•°æ®ç”Ÿæˆè¯¦ç»†çš„è¯Šæ–­å°è±¡ã€‚
è¦æ±‚ï¼š
1. ä½¿ç”¨ä¸“ä¸šçš„ä¸­æ–‡åŒ»å­¦æœ¯è¯­
2. æ˜ç¡®æè¿°å˜åŒ–è¶‹åŠ¿å’Œå¹…åº¦
3. å¼•ç”¨ RECIST 1.1 æ ‡å‡†è¿›è¡Œè¯„ä¼°
4. ç»™å‡ºæ˜ç¡®çš„ç–—æ•ˆè¯„ä¼°
5. åˆ†æé…å‡†è´¨é‡å¯¹ç»“æœçš„å½±å“
6. æè¿°è¦è¯¦ç»†ã€ä¸“ä¸šã€å‡†ç¡®"""
        
        reg_info = ""
        if registration_results:
            reg_info = f"\né…å‡†ç»“æœ:\n```json\n{self._safe_json_dumps(registration_results)}\n```"
        
        user_prompt = f"""åŸºçº¿æ£€æŸ¥å‘ç°:
```json
{self._safe_json_dumps(baseline_findings)}
```

éšè®¿æ£€æŸ¥å‘ç°:
```json
{self._safe_json_dumps(followup_findings)}
```

å˜åŒ–æ£€æµ‹åˆ†æ:
```json
{self._safe_json_dumps(change_results)}
```{reg_info}

è¯·ç”Ÿæˆè¯¦ç»†çš„çºµå‘å¯¹æ¯”è¯Šæ–­å°è±¡ï¼ˆä½¿ç”¨ä¸­æ–‡ï¼Œä¸“ä¸šæœ¯è¯­ï¼‰:"""
        
        result = self._call_llm(system_prompt, user_prompt)
        return result if result else self._generate_longitudinal_impression_template(
            baseline_findings, followup_findings, change_results
        )
    
    def _generate_longitudinal_recommendations_with_llm(
        self,
        baseline_findings: List[Dict[str, Any]],
        followup_findings: List[Dict[str, Any]],
        change_results: Dict[str, Any],
        registration_results: Dict[str, Any] = None
    ) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆçºµå‘å¯¹æ¯”å»ºè®®ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        system_prompt = """ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„è‚¿ç˜¤ç§‘åŒ»ç”Ÿã€‚è¯·æ ¹æ®å½±åƒå¯¹æ¯”ç»“æœç”Ÿæˆè¯¦ç»†çš„æ²»ç–—å»ºè®®ã€‚
è¦æ±‚ï¼š
1. ä½¿ç”¨ä¸­æ–‡ï¼Œä¸“ä¸šæœ¯è¯­
2. å»ºè®®åŸºäº RECIST è¯„ä¼°ç»“æœ
3. è€ƒè™‘å¤šå­¦ç§‘åä½œ (MDT)
4. ç»™å‡ºå…·ä½“çš„éšè®¿è®¡åˆ’å’Œæ—¶é—´
5. è€ƒè™‘æ‚£è€…ä¸ªä½“åŒ–æ²»ç–—
6. å»ºè®®è¦è¯¦ç»†ã€å¯æ“ä½œã€æœ‰é’ˆå¯¹æ€§"""
        
        reg_info = ""
        if registration_results:
            reg_info = f"\né…å‡†ç»“æœ:\n```json\n{self._safe_json_dumps(registration_results)}\n```"
        
        user_prompt = f"""åŸºçº¿æ£€æŸ¥å‘ç°:
```json
{self._safe_json_dumps(baseline_findings)}
```

éšè®¿æ£€æŸ¥å‘ç°:
```json
{self._safe_json_dumps(followup_findings)}
```

å˜åŒ–æ£€æµ‹ç»“æœ:
```json
{self._safe_json_dumps(change_results)}
```{reg_info}

è¯·ç”Ÿæˆè¯¦ç»†çš„ä¸´åºŠæ²»ç–—å»ºè®®ï¼ˆä½¿ç”¨ä¸­æ–‡ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰:"""
        
        result = self._call_llm(system_prompt, user_prompt)
        return result if result else self._generate_longitudinal_recommendations_template(
            baseline_findings, followup_findings, change_results
        )
    
    def _calculate_interval(self, baseline_date: str, followup_date: str) -> str:
        """è®¡ç®—æ£€æŸ¥é—´éš”"""
        try:
            from datetime import datetime
            b_date = datetime.strptime(baseline_date, "%Y-%m-%d")
            f_date = datetime.strptime(followup_date, "%Y-%m-%d")
            days = (f_date - b_date).days
            
            if days < 30:
                return f"{days} å¤©"
            elif days < 365:
                months = days // 30
                return f"çº¦ {months} ä¸ªæœˆ"
            else:
                years = days // 365
                months = (days % 365) // 30
                if months > 0:
                    return f"çº¦ {years} å¹´ {months} ä¸ªæœˆ"
                return f"çº¦ {years} å¹´"
        except:
            return "æœªçŸ¥"
    
    def _get_technique_text(self, modality: str) -> str:
        """è·å–æŠ€æœ¯å‚æ•°æè¿°"""
        if modality == "CT":
            return """- æ‰«æè®¾å¤‡: å¤šæ’èºæ—‹ CT
- æ‰«æèŒƒå›´: å…¨èƒ¸éƒ¨
- å±‚åš: 1.0-1.5 mm
- é‡å»ºç®—æ³•: æ ‡å‡†ç®—æ³•
- çª—ä½/çª—å®½: è‚ºçª— (-600/1500)ï¼Œçºµéš”çª— (40/400)"""
        elif modality == "MRI":
            return """- æ‰«æè®¾å¤‡: 1.5T/3.0T MRI
- åºåˆ—: T1WI, T2WI, DWI
- å±‚åš: 3-5 mm"""
        else:
            return f"- æ£€æŸ¥æ¨¡æ€: {modality}"
    
    def save_report(self, report: str, output_path: Path, format: str = "md") -> Path:
        """
        ä¿å­˜æŠ¥å‘Š
        
        Args:
            report: æŠ¥å‘Šå†…å®¹
            output_path: è¾“å‡ºè·¯å¾„
            format: æ ¼å¼ ("md", "html", "pdf")
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        if format == "md":
            output_path = output_path.with_suffix(".md")
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report)
        
        elif format == "html":
            output_path = output_path.with_suffix(".html")
            html = self._markdown_to_html(report)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html)
        
        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        return output_path
    
    def _markdown_to_html(self, markdown_text: str) -> str:
        """å°† Markdown è½¬æ¢ä¸º HTML"""
        try:
            import markdown
            html_body = markdown.markdown(markdown_text, extensions=['tables', 'fenced_code'])
        except ImportError:
            # ç®€å•çš„ Markdown è½¬æ¢
            html_body = markdown_text.replace('\n', '<br>\n')
        
        html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NeuroScan AI è¯Šæ–­æŠ¥å‘Š</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }}
        h1 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }}
        h2 {{ color: #34495e; margin-top: 30px; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
        th {{ background-color: #3498db; color: white; }}
        tr:nth-child(even) {{ background-color: #f2f2f2; }}
        hr {{ border: none; border-top: 1px solid #ddd; margin: 30px 0; }}
        .footer {{ color: #7f8c8d; font-size: 0.9em; margin-top: 30px; }}
    </style>
</head>
<body>
{html_body}
</body>
</html>"""
        return html

